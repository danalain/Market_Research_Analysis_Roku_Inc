{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News API Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import News API and Natural Language Toolkit\n",
    "from newsapi.newsapi_client import NewsApiClient\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=os.environ[\"news_api\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Headline and Sentiment Analyzer Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current date and the date from one month ago using the ISO format\n",
    "current_date = pd.Timestamp(\"2021-01-18\", tz=\"America/New_York\").isoformat()\n",
    "past_date = pd.Timestamp(\"2020-12-18\", tz=\"America/New_York\").isoformat()\n",
    "\n",
    "# Use newsapi client to get most relevant 20 headlines per day in the past month\n",
    "def get_headlines(keyword):\n",
    "    all_headlines = []\n",
    "    all_dates = []    \n",
    "    date = datetime.strptime(current_date[:10], \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(past_date[:10], \"%Y-%m-%d\")\n",
    "    print(f\"Fetching news about '{keyword}'\")\n",
    "    print(\"*\" * 30)\n",
    "    while date > end_date:\n",
    "        print(f\"retrieving news from: {date}\")\n",
    "        articles = newsapi.get_everything(\n",
    "            q=keyword,\n",
    "            from_param=str(date),\n",
    "            to=str(date),\n",
    "            language=\"en\",\n",
    "            sort_by=\"relevancy\",\n",
    "            page=1,\n",
    "        )\n",
    "        headlines = []\n",
    "        for i in range(0, len(articles[\"articles\"])):\n",
    "            headlines.append(articles[\"articles\"][i][\"title\"])\n",
    "        all_headlines.append(headlines)\n",
    "        all_dates.append(date)\n",
    "        date = date - timedelta(days=1)\n",
    "    return all_headlines, all_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Sentiment Analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment calculation based on compound score\n",
    "def get_sentiment(score):\n",
    "    \"\"\"\n",
    "    Calculates the sentiment based on the compound score.\n",
    "    \"\"\"\n",
    "    result = 0  # Neutral by default\n",
    "    if score >= 0.05:  # Positive\n",
    "        result = 1\n",
    "    elif score <= -0.05:  # Negative\n",
    "        result = -1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news about 'roku'\n",
      "******************************\n",
      "retrieving news from: 2021-01-15 00:00:00\n",
      "retrieving news from: 2021-01-14 00:00:00\n",
      "retrieving news from: 2021-01-13 00:00:00\n",
      "retrieving news from: 2021-01-12 00:00:00\n",
      "retrieving news from: 2021-01-11 00:00:00\n",
      "retrieving news from: 2021-01-10 00:00:00\n",
      "retrieving news from: 2021-01-09 00:00:00\n",
      "retrieving news from: 2021-01-08 00:00:00\n",
      "retrieving news from: 2021-01-07 00:00:00\n",
      "retrieving news from: 2021-01-06 00:00:00\n",
      "retrieving news from: 2021-01-05 00:00:00\n",
      "retrieving news from: 2021-01-04 00:00:00\n",
      "retrieving news from: 2021-01-03 00:00:00\n",
      "retrieving news from: 2021-01-02 00:00:00\n",
      "retrieving news from: 2021-01-01 00:00:00\n",
      "retrieving news from: 2020-12-31 00:00:00\n",
      "retrieving news from: 2020-12-30 00:00:00\n",
      "retrieving news from: 2020-12-29 00:00:00\n",
      "retrieving news from: 2020-12-28 00:00:00\n",
      "retrieving news from: 2020-12-27 00:00:00\n",
      "retrieving news from: 2020-12-26 00:00:00\n",
      "retrieving news from: 2020-12-25 00:00:00\n",
      "retrieving news from: 2020-12-24 00:00:00\n",
      "retrieving news from: 2020-12-23 00:00:00\n",
      "retrieving news from: 2020-12-22 00:00:00\n",
      "retrieving news from: 2020-12-21 00:00:00\n",
      "retrieving news from: 2020-12-20 00:00:00\n",
      "retrieving news from: 2020-12-19 00:00:00\n",
      "retrieving news from: 2020-12-18 00:00:00\n",
      "retrieving news from: 2020-12-17 00:00:00\n",
      "retrieving news from: 2020-12-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "roku_headlines, roku_dates = get_headlines(\"roku\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the roku_headlines from list of list to just list\n",
    "roku_list = [headline for sublist in roku_headlines for headline in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to cancel your account at Netflix, Amazon ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At CES 2021, TCL put all other TV makers on no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything to know about Discovery+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How the Xbox’s default “instant on” feature co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What Must Roku Do To Justify Its Lofty Share P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  How to cancel your account at Netflix, Amazon ...\n",
       "1  At CES 2021, TCL put all other TV makers on no...\n",
       "2                Everything to know about Discovery+\n",
       "3  How the Xbox’s default “instant on” feature co...\n",
       "4  What Must Roku Do To Justify Its Lofty Share P..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# roku_list\n",
    "# Convert the new list into a dataframe\n",
    "roku_df = pd.DataFrame(roku_list)\n",
    "roku_df.rename(columns={0: \"title\"}, inplace = True)\n",
    "roku_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roku_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment scores dictionaries\n",
    "roku_sent = {\n",
    "    \"roku_compound\": [],\n",
    "    \"roku_sentiment\": [],\n",
    "}\n",
    "\n",
    "# Get sentiment for the tweets\n",
    "for index, row in roku_df.iterrows():\n",
    "    try:\n",
    "        # Sentiment scoring with VADER\n",
    "        roku_sentiment = analyzer.polarity_scores(row[\"title\"])\n",
    "        roku_sent[\"roku_compound\"].append(roku_sentiment[\"compound\"])\n",
    "        roku_sent[\"roku_sentiment\"].append(get_sentiment(roku_sentiment[\"compound\"]))\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "# Attaching sentiment columns to the News DataFrame\n",
    "roku_sentiment_df = pd.DataFrame(roku_sent)\n",
    "roku_df = roku_df.join(roku_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>roku_compound</th>\n",
       "      <th>roku_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>Roku and WarnerMedia have reached an agreement...</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>Finally: HBO Max Coming to Roku After Lengthy ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>The HBO Max Roku app is launching just in time...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>What is Acorn TV? Everything you need to know ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>HBO Max Finally Coming to Roku as ‘Wonder Woma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  roku_compound  \\\n",
       "615  Roku and WarnerMedia have reached an agreement...        -0.3818   \n",
       "616  Finally: HBO Max Coming to Roku After Lengthy ...         0.0000   \n",
       "617  The HBO Max Roku app is launching just in time...         0.0000   \n",
       "618  What is Acorn TV? Everything you need to know ...         0.0000   \n",
       "619  HBO Max Finally Coming to Roku as ‘Wonder Woma...            NaN   \n",
       "\n",
       "     roku_sentiment  \n",
       "615            -1.0  \n",
       "616             0.0  \n",
       "617             0.0  \n",
       "618             0.0  \n",
       "619             NaN  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roku_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "roku_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "roku_df.to_csv(\"../Data/roku_newsapi.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
